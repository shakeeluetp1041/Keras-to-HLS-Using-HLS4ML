{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40fcdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,InputLayer,Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from callbacks import all_callbacks\n",
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc83d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = fetch_openml('hls4ml_lhc_jets_hlf') \n",
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08558874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns exploration\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of target: {y.shape}\")\n",
    "feature_names = X.columns.tolist()\n",
    "print(\"Feature names:\", feature_names)\n",
    "# 2. Check for null values in each column\n",
    "null_values = X.isnull().sum()\n",
    "print(\"Null values in each column:\")\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c15c4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_le= le.fit_transform(y) # y_le numpy array, shape is 83000\n",
    "y_cat = to_categorical(y_le, 5)  #y_cat  numpy array, shape is 83000,5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[25])\n",
    "y_cat[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac08db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f0f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(batch_input_shape=(None, 16), name='input_1'))\n",
    "#model.add(Input(shape=(16,), name='input_1')) \n",
    "model.add(Dense(64, input_shape=(16,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu1'))\n",
    "model.add(Dense(32, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu2'))\n",
    "model.add(Dense(32, name='fc3', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu3'))\n",
    "model.add(Dense(5, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='softmax', name='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e976e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False\n",
    "if train:\n",
    "    adam = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    cb = all_callbacks(stop_patience=5,\n",
    "        lr_factor=0.5,\n",
    "        lr_patience=2,\n",
    "        lr_epsilon=0.001,\n",
    "        lr_cooldown=1,\n",
    "        lr_minimum=1e-5,\n",
    "        outputDir='model_1',\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train_norm,\n",
    "        y_train,\n",
    "        batch_size=1024,\n",
    "        epochs=10,\n",
    "        validation_split=0.25,\n",
    "        shuffle=True,\n",
    "        callbacks=cb.callbacks_list,\n",
    "    )\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "    model = load_model('model_1/KERAS_check_best_model.h5')\n",
    "    print(\"Model loaded from disk.\")\n",
    "\n",
    "y_keras = model.predict(X_test_norm)\n",
    "y_keras.shape\n",
    "print(y_keras.shape)\n",
    "print(y_test.shape)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc872e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model_1/KERAS_check_best_model.h5')\n",
    "\"\"\"\n",
    "print(model.input_shape)\n",
    "import json\n",
    "model_arch = json.loads(model.to_json())\n",
    "print(json.dumps(model_arch['config']['layers'][0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c7cf0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import hls4ml\n",
    "# Directory where to save reports\n",
    "custom_dir = 'custom_data'\n",
    "config_file = 'custom_config.yaml'\n",
    "# Full path to the config file\n",
    "config_file_path = os.path.join(custom_dir, config_file)\n",
    "# Create directory if not exists\n",
    "if not os.path.exists(custom_dir):\n",
    "    os.makedirs(custom_dir)\n",
    "# Create the empty config file (overwrite if exists)\n",
    "with open(config_file_path, 'w') as f:\n",
    "    pass  # just create an empty file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a5fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YAML config file\n",
    "with open('custom_config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "import plotting\n",
    "#config = hls4ml.utils.config_from_keras_model(model, granularity='model', backend='Vitis')\n",
    "# Sets the configuration (you can do this by.yaml file), output is dictinary (backend dependent) of configurations\n",
    "from pprint import pprint \n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2489a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model o synthesizable HLS C++ code usin the backend dependent appropriate HLS toolchani\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, backend='Vitis', output_dir='model_1/hls4ml_prj', part='xc7z020clg400-1'\n",
    ")\n",
    "# Tutorial part:'xcu250-figd2104-2L-e'\n",
    "#PYNQ board part:'xc7z020clg400-1'\n",
    "hls_model.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()\n",
    "X_test_hls = np.ascontiguousarray(X_test_norm)\n",
    "y_hls = hls_model.predict(X_test_hls)\n",
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "print(\"hls4ml Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9728c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "classes = le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = le.classes_ \n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"i={i},class_name={class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d41852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = le.classes_\n",
    "\n",
    "# Binarize integer labels (should match y_cat)\n",
    "#y_test_bin = label_binarize(y_le, classes=range(len(classes)))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    y_true = y_test[:, i]\n",
    "    y_keras_score = y_keras[:, i]\n",
    "    y_hls_score = y_hls[:, i]\n",
    "\n",
    "    fpr_keras, tpr_keras, _ = roc_curve(y_true, y_keras_score)\n",
    "    auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "    fpr_hls, tpr_hls, _ = roc_curve(y_true, y_hls_score)\n",
    "    auc_hls = auc(fpr_hls, tpr_hls)\n",
    "\n",
    "    plt.plot(fpr_keras, tpr_keras, label=f'Keras {class_name} (AUC={auc_keras:.3f})')\n",
    "    plt.plot(fpr_hls, tpr_hls, linestyle='--', label=f'HLS {class_name} (AUC={auc_hls:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Add Vitis HLS path to the environment\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/data/opt/Xilinx/Vitis_HLS/2024.1/bin\"\n",
    "# +\"/data/opt/Xilinx/Vivado/2024.1\"\n",
    "# (Optional) Check it's visible to Python\n",
    "#os.system(\"which vitis_hls\")  # Should print the full path\n",
    "\n",
    "# Now run the build\n",
    "report=hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "r = report['CSynthesisReport']\n",
    "\n",
    "# Create a DataFrame for resource usage\n",
    "df = pd.DataFrame({\n",
    "    'Resource': ['BRAM_18K', 'DSP', 'FF', 'LUT', 'URAM'],\n",
    "    'Used': [int(r['BRAM_18K']), int(r['DSP']), int(r['FF']), int(r['LUT']), int(r['URAM'])],\n",
    "    'Available': [int(r['AvailableBRAM_18K']), int(r['AvailableDSP']), int(r['AvailableFF']), int(r['AvailableLUT']), int(r['AvailableURAM'])]\n",
    "})\n",
    "\n",
    "df['Utilization (%)'] = (df['Used'] / df['Available'] * 100).round(2)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock_latency = {\n",
    "    'Target Clock Period (ns)': r['TargetClockPeriod'],\n",
    "    'Estimated Clock Period (ns)': r['EstimatedClockPeriod'],\n",
    "    'Best Latency (cycles)': r['BestLatency'],\n",
    "    'Worst Latency (cycles)': r['WorstLatency'],\n",
    "    'Interval Min (cycles)': r['IntervalMin'],\n",
    "    'Interval Max (cycles)': r['IntervalMax'],\n",
    "}\n",
    "\n",
    "df_latency = pd.DataFrame(clock_latency.items(), columns=[\"Metric\", \"Value\"])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File path for resource report\n",
    "resources_report_file_path = os.path.join(report_dir, 'resources_report.tsv')\n",
    "latency_report_file_path   = os.path.join(report_dir, 'latency_report.tsv')\n",
    "df.to_csv(resources_report_file_path, sep='\\t', index=False)\n",
    "df_latency.to_csv(latency_report_file_path, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
